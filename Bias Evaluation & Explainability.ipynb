{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h1 style=\"font-size: 3em; line-height:2em\">Explainability and Bias Evaluation<br> with Tensorflow</h1> \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<h1> Alejandro Saucedo</h1>\n",
    "Chief Scientist, The Institute for Ethical AI & Machine Learning\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "[github.com/ethicalml/bias-analysis](github.com/ethicalml/bias-analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, mean_squared_error, roc_curve, auc\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import shap\n",
    "from keras.layers import Input, Dense, Flatten, \\\n",
    "    Concatenate, concatenate, Dropout, Lambda\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "import keras\n",
    "from livelossplot import PlotLossesKeras\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import scipy\n",
    "from scipy.cluster import hierarchy as hc\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "import math\n",
    "\n",
    "params = {\"ytick.color\" : \"w\",\n",
    "          \"xtick.color\" : \"w\",\n",
    "          \"axes.labelcolor\" : \"w\",\n",
    "          \"axes.edgecolor\" : \"w\"}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "shap.initjs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "label_column = \"loan\"\n",
    "csv_path = 'data/adult.data'\n",
    "csv_columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "                   \"occupation\", \"relationship\", \"ethnicity\", \"gender\", \"capital-gain\", \"capital-loss\",\n",
    "                   \"hours-per-week\", \"native-country\", \"loan\"]\n",
    "input_columns = [\"age\", \"workclass\", \"education\", \"education-num\", \"marital-status\",\n",
    "                   \"occupation\", \"relationship\", \"ethnicity\", \"gender\", \"capital-gain\", \"capital-loss\",\n",
    "                   \"hours-per-week\", \"native-country\"]\n",
    "categorical_features = [\"workclass\", \"education\", \"marital-status\",\n",
    "                       \"occupation\", \"relationship\", \"ethnicity\", \"gender\",\n",
    "                       \"native-country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data(df):\n",
    "    \n",
    "    if \"fnlwgt\" in df: del df[\"fnlwgt\"]\n",
    "    \n",
    "    tmp_df = df.copy()\n",
    "\n",
    "    # normalize data (this is important for model convergence)\n",
    "    dtypes = list(zip(tmp_df.dtypes.index, map(str, tmp_df.dtypes)))\n",
    "    for k,dtype in dtypes:\n",
    "        if dtype == \"int64\":\n",
    "            tmp_df[k] = tmp_df[k].astype(np.float32)\n",
    "            tmp_df[k] -= tmp_df[k].mean()\n",
    "            tmp_df[k] /= tmp_df[k].std()\n",
    "\n",
    "    cat_columns = tmp_df.select_dtypes(['object']).columns\n",
    "    tmp_df[cat_columns] = tmp_df[cat_columns].astype('category')\n",
    "    tmp_df[cat_columns] = tmp_df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    tmp_df[cat_columns] = tmp_df[cat_columns].astype('int8')\n",
    "    \n",
    "    return tmp_df\n",
    "\n",
    "def get_dataset_1():\n",
    "    tmp_df = df.copy()\n",
    "    tmp_df = tmp_df.groupby('loan') \\\n",
    "                .apply(lambda x: x.sample(100) if not x[\"loan\"].iloc[0] else x) \\\n",
    "                .reset_index(drop=True)\n",
    "    \n",
    "    X = tmp_df.drop(label_column, axis=1).copy()\n",
    "    y = tmp_df[label_column].astype(int).values.copy()\n",
    "    \n",
    "    return tmp_df, df_display.copy()\n",
    "\n",
    "def get_production_dataset():\n",
    "    tmp_df = df.copy()\n",
    "    \n",
    "    X = tmp_df.drop(label_column, axis=1).copy()\n",
    "    y = tmp_df[label_column].astype(int).values.copy()\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = \\\n",
    "        train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "    return X_valid, y_valid\n",
    "\n",
    "\n",
    "def get_dataset_2():\n",
    "    tmp_df = df.copy()\n",
    "    tmp_df_display = df_display.copy()\n",
    "    \n",
    "    X = tmp_df.drop(label_column, axis=1).copy()\n",
    "    y = tmp_df[label_column].astype(int).values.copy()\n",
    "    \n",
    "    X_display = tmp_df_display.drop(label_column, axis=1).copy()\n",
    "    y_display = tmp_df_display[label_column].astype(int).values.copy()\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = \\\n",
    "        train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "    return X, y, X_train, X_valid, y_train, y_valid, X_display, y_display\n",
    "    \n",
    "df_display = pd.read_csv(csv_path, names=csv_columns)\n",
    "df_display[label_column] = df_display[label_column].apply(lambda x: \">50K\" in x)\n",
    "df = prepare_data(df_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 style=\"font-size: 5em\">New Project!</h1>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Client wants to automate loan approval process\n",
    "\n",
    "<br>\n",
    "\n",
    "#### They have a manual process where a domain expert goes through applicants\n",
    "They want to automate this as they get 1m requests per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education-num       marital-status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship ethnicity   gender  capital-gain  \\\n",
       "0        Adm-clerical   Not-in-family     White     Male          2174   \n",
       "1     Exec-managerial         Husband     White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family     White     Male             0   \n",
       "3   Handlers-cleaners         Husband     Black     Male             0   \n",
       "4      Prof-specialty            Wife     Black   Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country   loan  \n",
       "0             0              40   United-States  False  \n",
       "1             0              13   United-States  False  \n",
       "2             0              40   United-States  False  \n",
       "3             0              40   United-States  False  \n",
       "4             0              40            Cuba  False  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data, df_display = get_dataset_1()\n",
    "\n",
    "df_display.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>-0.629133</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>3.664620</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>0.470539</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7699</th>\n",
       "      <td>1.203653</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1.912109</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>1.179399</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>0.397227</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.420053</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>0.612479</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>0.103982</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.134721</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  workclass  education  education-num  marital-status  \\\n",
       "3337 -0.629133          4          9       1.134721               0   \n",
       "4095  0.470539          4          9       1.134721               2   \n",
       "7699  1.203653          6         14       1.912109               6   \n",
       "3773  0.397227          4         11      -0.420053               2   \n",
       "1592  0.103982          4          9       1.134721               2   \n",
       "\n",
       "      occupation  relationship  ethnicity  gender  capital-gain  capital-loss  \\\n",
       "3337          12             1          4       1     -0.145918      3.664620   \n",
       "4095           3             0          1       1     -0.145918     -0.216656   \n",
       "7699          10             1          4       1     -0.145918     -0.216656   \n",
       "3773           1             0          4       1     -0.145918     -0.216656   \n",
       "1592          12             0          4       1     -0.145918     -0.216656   \n",
       "\n",
       "      hours-per-week  native-country  \n",
       "3337       -0.035429              39  \n",
       "4095       -0.035429              24  \n",
       "7699        1.179399              39  \n",
       "3773        0.612479              39  \n",
       "1592       -0.035429              39  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_data.drop(label_column, axis=1).copy()\n",
    "y = df_data[label_column].astype(int).values.copy()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "        train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_els = []\n",
    "    encoded_els = []\n",
    "    dtypes = list(zip(X.dtypes.index, map(str, X.dtypes)))\n",
    "    for k,dtype in dtypes:\n",
    "        input_els.append(Input(shape=(1,)))\n",
    "        if dtype == \"int8\":\n",
    "            e = Flatten()(Embedding(df[k].max()+1, 1)(input_els[-1]))\n",
    "        else:\n",
    "            e = input_els[-1]\n",
    "        encoded_els.append(e)\n",
    "    encoded_els = concatenate(encoded_els)\n",
    "\n",
    "    layer1 = Dropout(0.5)(Dense(100, activation=\"relu\")(encoded_els))\n",
    "    out = Dense(1, activation='sigmoid')(layer1)\n",
    "\n",
    "    # train model\n",
    "    model = Model(inputs=input_els, outputs=[out])\n",
    "    model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def f_in(X, m=None):\n",
    "    \"\"\"Preprocess input so it can be provided to a function\"\"\"\n",
    "    if m:\n",
    "        return [X.iloc[:m,i] for i in range(X.shape[1])]\n",
    "    else:\n",
    "        return [X.iloc[:,i] for i in range(X.shape[1])]\n",
    "\n",
    "def f_out(probs):\n",
    "    \"\"\"Convert probabilities into classes\"\"\"\n",
    "    return list((probs >= 0.5).astype(int).T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "\n",
    "model.fit(\n",
    "    f_in(X_train), y_train, epochs=50,\n",
    "    batch_size=512, shuffle=True, validation_data=(f_in(X_valid), y_valid),\n",
    "    callbacks=[PlotLossesKeras()], verbose=0, validation_split=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(f_in(X_valid), y_valid, verbose=1)\n",
    "print(\"Error %.4f: \" % score[0])\n",
    "print(\"Accuracy %.4f: \" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Accuracy is 98%\n",
    "\n",
    "# Time for PROD!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2am call....\n",
    "\n",
    "...what do you mean performing terrible?\n",
    "\n",
    "# Time to REVERT!\n",
    "\n",
    "<img src=\"files/subdir/image.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X_prod, y_prod = get_production_dataset()\n",
    "\n",
    "score = model.evaluate(f_in(X_prod), y_prod, verbose=1)\n",
    "\n",
    "print(\"Error %.4f: \" % score[0])\n",
    "print(\"Accuracy %.4f: \" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "probabilities = model.predict(f_in(X_valid))\n",
    "print(list(probabilities.T[0])[:10])\n",
    "\n",
    "pred = f_out(probabilities)\n",
    "print(pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "confusion = sklearn.metrics.confusion_matrix(y_valid, pred)\n",
    "confusion_scaled = confusion.astype(\"float\") / confusion.sum(axis=1)[:, np.newaxis]\n",
    "confusion_scaled_df = pd.DataFrame(confusion_scaled, index=[\"Denied\", \"Approved\"], columns=[\"Denied\", \"Approved\"])\n",
    "\n",
    "sn.heatmap(confusion_scaled_df, annot=True, fmt='.2f', center=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "confusion_df = pd.DataFrame(confusion,\n",
    "            index=[\"Actual Denied\", \"Actual Approved\"], \n",
    "            columns=[\"Preditced Denied\", \"Preditced Approved\"])\n",
    "\n",
    "sn.heatmap(confusion_df, annot=True, fmt='d', center=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc(y, probs):\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y, probs)\n",
    "\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(roc_auc)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.rcParams.update(params)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(y_valid, pred))\n",
    "\n",
    "plot_roc(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(15,7))\n",
    "sn.countplot(y_valid, ax=ax[0]) \n",
    "sn.countplot(y_prod, ax=ax[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_valid, y_train, y_valid, X_display, y_display \\\n",
    "    = get_dataset_2()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves(model, X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in list(np.logspace(0.6,4,dtype='int')):\n",
    "        if m >= len(X_train): break\n",
    "        model.fit(f_in(X_train,m), y_train[:m], epochs=50, batch_size=512, verbose=0)\n",
    "        y_train_predict = model.predict(f_in(X_train,m))\n",
    "        y_val_predict = model.predict(f_in(X_val))\n",
    "        y_train_predict = f_out(y_train_predict)\n",
    "        y_val_predict = f_out(y_val_predict)\n",
    "        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n",
    "        val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(model, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP for TF/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_predict(X):\n",
    "    values = model.predict([X[:,i] for i in range(X.shape[1])]).flatten()\n",
    "    return values\n",
    "\n",
    "shap_explainer = shap.KernelExplainer(shap_predict, X.iloc[:100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_idx = 0\n",
    "shap_x = X.iloc[shap_idx,:]\n",
    "shap_display_x = X_display.iloc[shap_idx,:]\n",
    "shap_values = shap_explainer.shap_values(shap_x, nsamples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Probability: \", probabilities[shap_idx])\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values, shap_display_x, matplotlib=True, figsize=(40, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_idx_multi_from = 15\n",
    "shap_idx_multi_to = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_x_multi = X.iloc[shap_idx_multi_from:shap_idx_multi_to,:]\n",
    "shap_display_multi = X_display.iloc[shap_idx_multi_from:shap_idx_multi_to,:]\n",
    "shap_y_multi = y[shap_idx_multi_from:shap_idx_multi_to]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_multi = shap_explainer.shap_values(shap_x_multi, nsamples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_explainer.expected_value, shap_values_multi, shap_display_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"hours-per-week\", \n",
    "                     shap_values_multi, \n",
    "                     shap_x_multi, \n",
    "                     display_features=shap_display_multi,\n",
    "                     axis_color='#FFFFFF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_multi, shap_x_multi, axis_color='#FFFFFF')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME on Keras+Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_lime_explainer = LimeTabularExplainer(\n",
    "                X_train.values,\n",
    "                feature_names=list(X_train.columns),\n",
    "                categorical_features=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lime_predict_proba(X):\n",
    "    values = model.predict([X[:,i] for i in range(X.shape[1])]).flatten()\n",
    "    prob_pairs = np.array([1-values, values]).T\n",
    "    return prob_pairs\n",
    "\n",
    "tf_lime_explanation = tf_lime_explainer.explain_instance(\n",
    "        X_train.iloc[1,:], lime_predict_proba, num_features=13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_lime_explanation.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_lime_explanation.show_in_notebook(show_table=True, show_all=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_analysis = X_display.copy()\n",
    "y_analysis = y_display.copy()\n",
    "df_analysis = X_analysis.copy()\n",
    "df_analysis[label_column] = y_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[label_column].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "cols = 5\n",
    "rows = math.ceil(float(X.shape[1]) / cols)\n",
    "for i, column in enumerate(X.columns):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    ax.set_title(column)\n",
    "    if X.dtypes[column] == np.object:\n",
    "        X[column].value_counts().plot(kind=\"bar\", axes=ax)\n",
    "    else:\n",
    "        X[column].hist(axes=ax)\n",
    "        plt.xticks(rotation=\"vertical\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gender\"].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flds = [\"gender\", \"age\", \"education-num\", \"capital-gain\", \n",
    "                  \"capital-loss\", \"hours-per-week\"]\n",
    "\n",
    "\n",
    "enc_summ = X_display[flds].groupby(\"gender\", as_index=False).mean()\n",
    "enc_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ethnicity\"].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_score(self, X, y, **kwargs):\n",
    "    input_test = [X[:,i] for i in range(X.shape[1])]\n",
    "    loss = self.evaluate(input_test, y)\n",
    "    if type(loss) is list:\n",
    "        # The first one is the error, the rest are metrics\n",
    "        return -loss[0]\n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perm = PermutationImportance(model, random_state=1, scoring=keras_score).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5_fi = eli5.explain_weights_df(perm, feature_names = X.columns.tolist())\n",
    "eli5_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5_fi.plot(\"feature\", \"weight\", \"barh\", figsize=(12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"marital-status\", \"loan\"]).size().plot(\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sit down with our clients to understand these perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendogram(corr):\n",
    "    corr_condensed = hc.distance.squareform(1-corr)\n",
    "    z = hc.linkage(corr_condensed, method=\"average\")\n",
    "    fig = plt.figure(figsize=(16,5))\n",
    "    dendrogram = hc.dendrogram(\n",
    "        z, labels=X_analysis.columns, orientation=\"left\", leaf_font_size=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.round(scipy.stats.spearmanr(X_analysis).correlation, 4)\n",
    "plot_dendogram(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_analysis.plot(\n",
    "    \"age\", \n",
    "    \"capital-gain\",\n",
    "    \"scatter\",\n",
    "    alpha=0.01,\n",
    "    figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, summary_df = info_plots.target_plot(\n",
    "    df=df, feature=\"age\", feature_name=\"age\", target=\"capital-gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def predict(self, X, **kwargs):\n",
    "        return self.model.predict([X.iloc[:,i] for i in range(X.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = ModelWrapper(model)\n",
    "    \n",
    "fig, axes, summary_df = info_plots.actual_plot(\n",
    "    model=mr, X=X, feature=\"gender\", feature_name=\"gender\", predict_kwds={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_sex = pdp.pdp_isolate(\n",
    "    model=mr, dataset=X, model_features=input_columns, feature='gender'\n",
    ")\n",
    "\n",
    "fig, axes = pdp.pdp_plot(pdp_sex, 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
